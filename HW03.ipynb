{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcePiW8SZqM5"
   },
   "source": [
    "## Homework 3 - Graphical Models - CS348 Spring 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBlnhSbzZq8X"
   },
   "source": [
    "**Description** - In this assignment, you will solve problems related to casual inference, conditional independence, graphical models, and anomaly detection.\n",
    "\n",
    "**Getting Started** - You should complete the assignment using your own installation of Python 3 and the packages numpy, pandas, matplotlib, seaborn, etc. Download the assignment from Canvas and unzip the file. This will create a directory with this file, 'HW03.ipynb'. I'd recommend looking through the assignment to see what questions are asked before starting.\n",
    "\n",
    "Note: You may need to install the seaborn visualization library. To do this run `conda install seaborn` or `pip install seaborn` in your terminal. The same is said for the bnlearn library, a library built for graphical models and bayesian networks. To install bnlearn, run `conda install bnlearn` or `pip install bnlearn` in the terminal. Or run `! pip install bnlearn` in the notebook itself. You'll need to restart and run the code again after first installing bnlearn. MAKE SURE TO ACTIVATE YOUR ENVIRONMENT IF INSTALLING PACKAGES IN THE TERMINAL.\n",
    "\n",
    "**Deliverables** - The assignment has a single deliverable: this jupyter notebook file saved as a PDF. Please answer all coding and writing questions in the body of this file. Once all of the answers are complete, download the file by navigating the following menus: File -> Download as -> PDF via LaTeX. Submit the downloaded PDF file on gradescope (if you are using Mac OS, we recommend using a browser other than Chrome). Otherwise, create a PDF using VSCode.\n",
    "\n",
    "Note: You will be writing the written responses in the dedicated **Part _ Written Response** cells. You'll be writing your code in the dedicate coding cells under `--- write code here ---`\n",
    "\n",
    "**Data Sets** - In this assignment, you will utilize a dataset from the UCI repository focused on obesity classification based on eating habits and physical condition. Dataset link [here](https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition) and paper link [here](https://pmc.ncbi.nlm.nih.gov/articles/PMC6710633/#sec1)\n",
    "\n",
    "**Academic Honesty Statement** â€”\n",
    "\n",
    "\n",
    "I encourage you to discuss and obtain help from other students with: (1) basic concepts covered in lectures or textbook; (2) assignment understanding (but not solutions); and (3) program implementation (but not design). All the solutions on assignments must be your own. Using other people's code for, or solutions to, the assignments is unacceptable. You are expected to take reasonable precautions to prevent others from using your work.\n",
    "\n",
    "Using other people's words directly without attribution is plagiarism, a serious breach of academic honesty. If you have received significant ideas or specific words from another student, a written source, or an AI system such as a large language model, this must be acknowledged with a citation.\n",
    "\n",
    "Academic dishonesty is prohibited in all programs of the University. Academic dishonesty includes but is not limited to: cheating, fabrication, plagiarism, and facilitating dishonesty. Appropriate sanctions may be imposed on any student who has committed an act of academic dishonesty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1745986280809,
     "user": {
      "displayName": "Ryan Hilton",
      "userId": "02703455748676042997"
     },
     "user_tz": 240
    },
    "id": "xE-EfxsO8-60",
    "outputId": "8e653d2a-b1c4-4ad7-863e-02e0dda61fa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# # If you are not working in google colab, you'll have to comment this code block\n",
    "# # If you are using google colab, fill in your folder path that contains the assignment materials.\n",
    "# from google.colab import drive\n",
    "# import os\n",
    "# drive.mount('/content/drive')\n",
    "# folder_path = \"/content/drive/Shareddrives/COMPSCI 348 (Spring 2025)/Assignment 3\"\n",
    "# os.chdir(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b8hR0AP43Pp"
   },
   "source": [
    "# Problem 1 - Graphical Models (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdGZeiC-5AEd"
   },
   "source": [
    "<img src=\"FirstImage.png\" alt=\"drawing\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4A8U_8f47Kl"
   },
   "source": [
    "### **Part 1** (4 points)\n",
    "\n",
    "1. Which nodes are parents of node D?\n",
    "2. Which nodes are children of node B?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUo5jjI85yRz"
   },
   "source": [
    "**Part 1 Written Response** (4 points)\n",
    "\n",
    "1. Nodes B, E, F are parents of node D.\n",
    "2. Node D and E are children of node B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qq2kMeei6XHS"
   },
   "source": [
    "### **Part 2** (6 points)\n",
    "\n",
    "1. Which nodes are descendants of node A?\n",
    "2. Which nodes have no descendants?\n",
    "3. Which nodes have no ascendants?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yy2PPtT6XHT"
   },
   "source": [
    "**Part 2 Written Response** (6 points)\n",
    "\n",
    "1. Nodes E, D, G are descendants of node A.\n",
    "2. Node G has no descendants. \n",
    "3. Nodes C, A, F have no ascendants. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4Ba4AgamvJs"
   },
   "source": [
    "### **Part 3** (4 points)\n",
    "\n",
    "What variables are potential causes of variable E?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "di8E2ienmvJ0"
   },
   "source": [
    "**Part 3 Written Response** (4 points)\n",
    "\n",
    "Nodes B and A have direct relationship to effect variable E. \n",
    "Node C has a indirect relationship to effect variable E through B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9-qen_86ZQ_"
   },
   "source": [
    "### **Part 4** (5 points)\n",
    "\n",
    "List any colliders present in the graphical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNeCNMpU6ZRA"
   },
   "source": [
    "**Part 4 Written Response** (5 points)\n",
    "\n",
    "Nodes: D, E, G\n",
    "\n",
    "B -> D <- F,\n",
    "\n",
    "B -> D <- E,\n",
    "\n",
    "E -> D <- F,\n",
    "\n",
    "D -> G <- H\n",
    "\n",
    "B -> E <- A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rml8Ec946Ziy"
   },
   "source": [
    "### **Part 5** (8 points)\n",
    "\n",
    "Which of the following pairs of variables are independent with an empty conditioning set?\n",
    "\n",
    "1. <H,D>\n",
    "2. <C,F>\n",
    "3. <B,G>\n",
    "4. <A,H>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88qCm1Wv6Ziy"
   },
   "source": [
    "**Part 5 Written Response** (8 points)\n",
    "\n",
    "<H, D> have a path (H -> F -> D); therefore dependent.\n",
    "\n",
    "<C, F> have no path without colliders; therefore independent.\n",
    "\n",
    "<B, G> have a path (B -> D -> G); therefore dependent.\n",
    "\n",
    "<A, H> have no path without colliders; therefore independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQMG6Vse6Z50"
   },
   "source": [
    "### **Part 6** (6 points)\n",
    "\n",
    "For each pair of variables, determine if they are d-separated given D? If they are not d-separated, show all d-connecting paths\n",
    "\n",
    "1. <B,G>\n",
    "2. <A,F>\n",
    "3. <A,B>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxiFjhBF6Z51"
   },
   "source": [
    "**Part 6 Written Response** (6 points)\n",
    "\n",
    "1. <B, G> are not D-separated because the path from (B->D->G) has no colliders.\n",
    "2. <A, F> are D-separated because every path from A to F (A->E<-B->D<-F), (A->E<-B->D->G<-H<-F), (A->E->D->G<-H<-F), (A->E->D<-F) has a collider.\n",
    "3. <A, B> are D-separated because every path from A to B (A->E<-B), (A->E->D<-B) has a collider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSV38I0t70hO"
   },
   "source": [
    "### **Part 7** (6 points)\n",
    "\n",
    "For each of the following conditional independence statements, state whether they are or are NOT implied by the graph? <br>\n",
    "\n",
    "1. $H \\!\\perp\\!\\!\\!\\perp E | G$\n",
    "2. $A \\!\\perp\\!\\!\\!\\perp C | B, E$\n",
    "3. $F \\!\\perp\\!\\!\\!\\perp B | D$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YA5X7NM70hY"
   },
   "source": [
    "**Part 7 Written Response** (6 points)\n",
    "1. $H \\!\\perp\\!\\!\\!\\perp E | G$ is not implied by the graph because there is an active path from E to H (E->D->G<-H). G does not block the path as a collider because it is given. Therefore variables are not D separated and aren't conditionally independent.\n",
    "\n",
    "2. $A \\!\\perp\\!\\!\\!\\perp C | B, E$ is not implied by the graph because there is an active path from C to A (C->B->E<-A). E does not block the path as a collider because it is given. Therefore variables are not D separated and aren't conditionally independent.\n",
    "\n",
    "3. $F \\!\\perp\\!\\!\\!\\perp B | D$ is is not implied by the graph because there is an active path from B to F (B->D<-F). D does not the block the path as a collider because it is given. Therefore variables are not D separated and aren't conditionally independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYWmLO5wno1T"
   },
   "source": [
    "### **Part 8** (6 points)\n",
    "\n",
    "If we were to intervene on variable D, how would this change the graphical model? Specify which nodes/edges change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1zgqtFKno1c"
   },
   "source": [
    "**Part 8 Written Response** (6 points)\n",
    "\n",
    "If we intervene on variable D, then all incoming edges go away because D no longer dependents on other variables (B, E, F)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrTE5nCK7f8Z"
   },
   "source": [
    "### **Part 9** (5 points)\n",
    "\n",
    "Give the expression for the factorized joint probability distribution of all the variables (A, B, C, D, E, F, G, H) that is specifically implied by this graphical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5FzS9xv7f8j"
   },
   "source": [
    "**Part 9 Written Response** (5 points)\n",
    "\n",
    "P(A, B, C, D, E, F, G, H) = P(A) * P(C) * P(F) * P(B|C) * P(E |A, B) * P(D | B, E, F) * P(H|F) * P(G| D, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeQ0ItPbBRYy"
   },
   "source": [
    "# Problem 2: Application - Obesity Inference (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp-b6S5eBRw7"
   },
   "source": [
    "In this problem you will use the ``bnlearn`` package to learn the structure of a causal graphical model from data, parameterize the graph, i.e., learn the values of the conditional probability distributions (CPDs), and perform inference using the learned model.\n",
    "\n",
    "We will be using a dataset from the UCI repository. Here's the link: https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition\n",
    "\n",
    "Familiarize yourself with the dataset and the variables before starting this problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkoEuA5FGxHz"
   },
   "outputs": [],
   "source": [
    "#! pip install bnlearn # Uncomment this if you want to install the bnlearn package from inside the notebook rather than the terminal\n",
    "import numpy as np\n",
    "import bnlearn as bn # You will need to restart the kernel and re-run the code to properly import bnlearn.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMXbH1tbKy5m"
   },
   "outputs": [],
   "source": [
    "# DO NOT ALTER\n",
    "data = pd.read_csv(\"obesity_data.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T16QM_h1SrSy"
   },
   "outputs": [],
   "source": [
    "# DO NOT ALTER\n",
    "# Labels used from the PubMed paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC6710633/#sec1\n",
    "# Bins were created independently from the paper\n",
    "data['Activity Level'] = pd.cut(x=data[\"FAF\"], bins=[-1,0.5,1.5,2.5,3.5],\n",
    "                               labels=[\"No activity\",\"1 or 2 days\",\"2 or 4 days\",\"4 or 5 days\"])\n",
    "data['Veggie Intake'] = pd.cut(x=data[\"FCVC\"], bins=[0.5,1.5,2.5,3.5],\n",
    "                               labels=[\"Never\",\"Sometimes\",\"Always\"])\n",
    "\n",
    "data['No. Main Meals'] = pd.cut(x=data[\"NCP\"], bins=[0.5,2.0,3.5,4.5],\n",
    "                               labels=[\"Between 1 and 2\",\"Three\",\"More than three\"])\n",
    "\n",
    "data['H2O Intake'] = pd.cut(x=data[\"CH2O\"], bins=[0.5,1.5,2.5,3.5],\n",
    "                               labels=[\"Less than 1L\",\"Between 1L and 2L\",\"More than 2L\"])\n",
    "\n",
    "data['Tech Use'] = pd.cut(x=data[\"TUE\"], bins=[-0.5,0.5,1.5,2.5],\n",
    "                               labels=[\"0-2 Hours\",\"3-5 Hours\",\"More than 5 hours\"])\n",
    "\n",
    "# These labels and bins were created independently from the paper\n",
    "data['Binned Age'] = pd.cut(x=data['Age'], bins=[0, 3, 18, 63, 99],\n",
    "                            labels=['Baby', 'Child', 'Adult', 'Elderly'])\n",
    "data['Binned Height'] = pd.cut(x=data[\"Height\"], bins=[0,1.6,1.8,2.5], # meters\n",
    "                               labels=[\"Short\",\"Medium\",\"Tall\"])\n",
    "data[\"Binned Obesity Level\"] = data[\"NObeyesdad\"].apply(lambda x: \"Insufficient\" if 'Insufficient' in x else \\\n",
    " (\"Normal\" if 'Normal' in x else (\"Overweight\" if \"Overweight\" in x else \"Obese\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1dtCsybXSfn"
   },
   "outputs": [],
   "source": [
    "# DO NOT ALTER\n",
    "data_subset = data.loc[:, (data.nunique() < 8).values]\n",
    "data_subset.drop(columns=[\"SMOKE\",\"FAVC\",], inplace=True)\n",
    "data_subset.rename(columns={\"CAEC\": \"Food Between Meals\", \"SCC\": \"Monitor Calories\", \"CALC\": \"Alcohol Intake\", \"MTRANS\": \"Transportation\", \"NObeyesdad\": \"Obesity Level\"}, inplace=True)\n",
    "\n",
    "data_subset_bin = data_subset.drop(columns=[\"Obesity Level\"]).rename(columns={\"Binned Obesity Level\":\"Obesity Level\"})\n",
    "data_subset = data_subset.drop(columns=[\"Binned Obesity Level\"])\n",
    "\n",
    "# data_subset.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQwvnrKpR5pY"
   },
   "outputs": [],
   "source": [
    "# Here are the possible values for each variable\n",
    "for i in data_subset:\n",
    "  print(i, \": \", data_subset[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2hiVdjEBZNY"
   },
   "source": [
    "### **Part 1** (6 points)\n",
    "\n",
    "The bnlearn library has a method for learning the structure of a graphical model describing the dependencies across variables. Use `bn.structure_learning` to learn the DAG. Then use `bn.plot_graphviz(DAG)` function to plot the learned DAG.\n",
    "\n",
    "If this plot function doesn't work. You can also try `bn.plot(DAG)`. The following arguments may also obe useful:<br>\n",
    "`node_color='white', params_static={'layout':'planar_layout', 'arrowsize': 50}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puI3XzBqZs8g"
   },
   "outputs": [],
   "source": [
    "# Part 1 Solution\n",
    "random.seed(0)\n",
    "# --- write code here ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYxHk6DtoC8B"
   },
   "source": [
    "### **Part 2** (2 points)\n",
    "\n",
    "Display the learned DAG as an adjacency matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gd7vv5BYl8PO"
   },
   "outputs": [],
   "source": [
    "# Part 2 Solution\n",
    "\n",
    "# --- write code here ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWA1UiRkoFq0"
   },
   "source": [
    "### **Part 3** (6 points)\n",
    "\n",
    "Use `parameter_learning.fit` to estimate the parameters of the graphical model using the `bayes` method. Store the conditional probability distributions learned for the variables in your graph using `bn.print_CPD` into an object named `CPDs`. I would recommend using `verbose=0` in these function calls to curb the printed output length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "-cMlFpqGNnIZ"
   },
   "outputs": [],
   "source": [
    "# Part 3 Solution\n",
    "\n",
    "# --- write code here ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wyQFOZxB0U9"
   },
   "source": [
    "### **Part 4** (7 points)\n",
    "\n",
    "Using the CPDs object you saved from part 3, compute the following probabilities/distributions. In the off chance that your graphical model is different than the answer, use the `bn.inference.fit` function similar to Part 5.\n",
    "\n",
    "1. What is the probability that a person is considered normal weight given that they eat frequently between meals?\n",
    "2. What is the probability distribution P(**Activity Level** | Obesity Level=Obesity_Type_III)? Hint: Your answer should be a vector of probabilities\n",
    "3. What is the probability that a person is female given they are considered to have insufficient weight and no family history of overweight problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9jetffCbOIv"
   },
   "outputs": [],
   "source": [
    "# Part 4 Solution\n",
    "\n",
    "# 1. (2 points)\n",
    "# --- write code here ---\n",
    "\n",
    "# 2. (3 points)\n",
    "# --- write code here ---\n",
    "\n",
    "# 3. (2 points)\n",
    "# --- write code here ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8QemqK79kUd"
   },
   "source": [
    "**Part 4 Written Response** (5 points)\n",
    "\n",
    "1.\n",
    "2.\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FM56GJooJ6d"
   },
   "source": [
    "### **Part 5** (9 points)\n",
    "\n",
    "Some probabilities we are interested in aren't directly captured by the CPDs and require Bayes' Rule to compute. Let's use `bn.inference.fit` to perform inference on the graph. Compute the probabilities of the following questions:\n",
    "\n",
    "- Q1) What is the probability of a person being class III obese, given their transportation is usually walking?\n",
    "- Q2) What is the probability of a person being normal weight given they use technological devices for less than 2 hours a day and they drink between 1 and 2 liters of water per day?\n",
    "- Q3) What is the probability that someone frequently consumes food between meals given they monitor their calories and they are considered to have insufficient weight?\n",
    "- Q4) What is the probability distribution P(**family_history_with_overweight**, **Gender** | Alcohol=\"Always\")? Hint: the answer should be a vector with a label for each value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMCQ2zu-PJkq"
   },
   "outputs": [],
   "source": [
    "# Part 5 Solution\n",
    "\n",
    "# 1 (2 points)\n",
    "# --- write code here ---\n",
    "\n",
    "# 2 (2 points)\n",
    "# --- write code here ---\n",
    "\n",
    "# 3 (2 points)\n",
    "# --- write code here ---\n",
    "\n",
    "# 4 (3 points)\n",
    "# --- write code here ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWy8Y5B1Zt4j"
   },
   "source": [
    "**Part 5 Written Response** (5 points)\n",
    "\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxkhjZ6GbkF2"
   },
   "source": [
    "### **Part 6** (6 points)\n",
    "\n",
    "**Using the CPD** for Activity Level, create a plot showing the relationship between Activity Level and Obesity Level. What insights can you draw from this plot?\n",
    "\n",
    "For example, plot the different Obesity Level classes on the x-axis, have a line for each Activity Level, and have the probability that a particular Activity Level occurs given the Obesity Level on the y-axis.\n",
    "\n",
    "I'd recommend using `seaborn` plotting library for this, specifically the `catplot` function: [(link)](https://seaborn.pydata.org/generated/seaborn.catplot.html). It can take pandas dataframes as input, and you can specify which variable goes on the x, y, color, or column/row axes easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5A2iEWS0VelU"
   },
   "outputs": [],
   "source": [
    "# Part 6 Solution\n",
    "\n",
    "# --- write code here ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkfW9VKVy36D"
   },
   "source": [
    "**Part 6 Written Response** (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfaD7OIBhLOU"
   },
   "source": [
    "### **Part 7** (8 points)\n",
    "\n",
    "Here I give the code to generate another type of plot. Instead of using the CPD for activity level which tells us what the probability is that someone has a specific activity level given they their obesity classification, we are using Bayes' rule to get another probability: the probability that someone is of a particular obesity level given they their activity level.\n",
    "\n",
    "Compare the figure you made in the previous part to the figure here. What does each figure communicate? If we only know someone's activity level but want to predict what obesity level they might be, which plot would we want to see more to make this prediction?\n",
    "\n",
    "Just set `DAG` equal to your bayesian network model that you've developed and run the following two codeblocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "90kKnJD3cLTY"
   },
   "outputs": [],
   "source": [
    "# --- write code here ---\n",
    "dag = None\n",
    "# --- end code here\n",
    "\n",
    "q1 = bn.inference.fit(dag, variables=[\"Obesity Level\"], evidence={\"Activity Level\":\"No activity\"}, verbose=0)\n",
    "q2 = bn.inference.fit(dag, variables=[\"Obesity Level\"], evidence={\"Activity Level\":\"1 or 2 days\"}, verbose=0)\n",
    "q3 = bn.inference.fit(dag, variables=[\"Obesity Level\"], evidence={\"Activity Level\":\"2 or 4 days\"}, verbose=0)\n",
    "q4 = bn.inference.fit(dag, variables=[\"Obesity Level\"], evidence={\"Activity Level\":\"4 or 5 days\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OshKBT89deRA"
   },
   "outputs": [],
   "source": [
    "q6_df=pd.concat([q1.df,q2.df,q3.df,q4.df])\n",
    "q6_df['Activity Level'] = np.repeat(['No activity','1 or 2 days','2 or 4 days', '4 or 5 days'],[7,7,7,7])\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=q6_df, x=\"Obesity Level\", y=\"p\", hue=\"Activity Level\",\n",
    "    kind=\"point\", height=5, aspect=1.25, palette=\"Blues\",\n",
    "    order=[\"Insufficient_Weight\", \"Normal_Weight\",\"Overweight_Level_I\",\"Overweight_Level_II\",\"Obesity_Type_I\",\"Obesity_Type_II\",\"Obesity_Type_III\"],\n",
    "    hue_order = [\"No activity\",\"1 or 2 days\",\"2 or 4 days\",\"4 or 5 days\"]\n",
    ")\n",
    "\n",
    "g.tick_params(axis='x', rotation=45)\n",
    "g.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwYSylm-cLEV"
   },
   "source": [
    "**Part 7 Written Response** (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47OMduHcvp6E"
   },
   "source": [
    "### **Part 8** (6 points)\n",
    "\n",
    "Here, we will use a binned version of the target variable. Instead of having seven classes, we will map the variable into four classes (Insufficient Weight, Normal Weight, Overweight, Obese). We've provided some code for you that performs structure learning on the data with the new target variable.\n",
    "\n",
    "Does binning the target variable affect the learned causal structure? What causal relationships changed? Why do you think the learned causal structure changes or does not change when we bin the target variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "7XpIXQqlv2Q7"
   },
   "outputs": [],
   "source": [
    "model = None # Put your model object from part 1 here.\n",
    "\n",
    "\n",
    "bin_model = bn.structure_learning.fit(data_subset_bin)\n",
    "bn.plot_graphviz(model)\n",
    "bn.plot_graphviz(bin_model)\n",
    "# G = bn.plot(model, params_static={'layout':'planar_layout'})\n",
    "# bn.plot(bin_model, pos=G['pos'])\n",
    "bn.compare_networks(model, bin_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQ9wxy2eTMXt75i/UFh5T3",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
